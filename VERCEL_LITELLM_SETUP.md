# Vercel'de LiteLLM KullanÄ±mÄ±

Vercel serverless ortamÄ±nda LiteLLM kullanmak iÃ§in birkaÃ§ seÃ§enek var.

## ğŸ¯ Ã–nerilen YÃ¶ntem: AyrÄ± LiteLLM Server

LiteLLM'i ayrÄ± bir sunucuda Ã§alÄ±ÅŸtÄ±rÄ±p, Vercel'den ona baÄŸlanÄ±n.

### SeÃ§enek 1: Railway (Ã–nerilen - Kolay)

1. **Railway'de LiteLLM Deploy:**
   - [Railway](https://railway.app) hesabÄ± oluÅŸturun
   - New Project â†’ Deploy from GitHub
   - LiteLLM iÃ§in bir repo oluÅŸturun veya direkt deploy edin

2. **Railway Environment Variables:**
```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
LITELLM_MASTER_KEY=your-master-key
```

3. **Vercel Environment Variables:**
```env
LITELLM_API_URL=https://your-litellm.railway.app
LITELLM_API_KEY=your-master-key
LITELLM_MODEL=gpt-3.5-turbo
```

### SeÃ§enek 2: Render (Ãœcretsiz Tier)

1. **Render'da LiteLLM Deploy:**
   - [Render](https://render.com) hesabÄ± oluÅŸturun
   - New Web Service
   - Docker image: `ghcr.io/berriai/litellm:main-latest`
   - Port: 4000

2. **Render Environment Variables:**
```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

3. **Vercel Environment Variables:**
```env
LITELLM_API_URL=https://your-litellm.onrender.com
LITELLM_API_KEY=your-master-key
LITELLM_MODEL=gpt-3.5-turbo
```

### SeÃ§enek 3: Fly.io (HÄ±zlÄ±)

1. **Fly.io'da LiteLLM Deploy:**
```bash
fly launch --image ghcr.io/berriai/litellm:main-latest
fly secrets set OPENAI_API_KEY=sk-...
fly secrets set ANTHROPIC_API_KEY=sk-ant-...
```

2. **Vercel Environment Variables:**
```env
LITELLM_API_URL=https://your-litellm.fly.dev
LITELLM_API_KEY=your-master-key
LITELLM_MODEL=gpt-3.5-turbo
```

### SeÃ§enek 4: Kendi Sunucunuz (VPS)

1. **Sunucuda LiteLLM Kur:**
```bash
pip install litellm
litellm --model gpt-3.5-turbo --port 4000
```

2. **Nginx Reverse Proxy (Opsiyonel):**
```nginx
server {
    listen 80;
    server_name your-litellm-domain.com;

    location / {
        proxy_pass http://localhost:4000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

3. **Vercel Environment Variables:**
```env
LITELLM_API_URL=https://your-litellm-domain.com
LITELLM_API_KEY=your-master-key
LITELLM_MODEL=gpt-3.5-turbo
```

## ğŸ”§ Vercel Environment Variables Ayarlama

### AdÄ±m 1: Vercel Dashboard'a Gidin
1. [Vercel Dashboard](https://vercel.com/dashboard)
2. Projenizi seÃ§in
3. Settings â†’ Environment Variables

### AdÄ±m 2: Environment Variables Ekleyin

**Production, Preview, Development iÃ§in:**

```env
# LiteLLM Configuration
LITELLM_API_URL=https://your-litellm-instance.com
LITELLM_API_KEY=your-master-key-or-provider-key
LITELLM_MODEL=gpt-3.5-turbo

# Provider API Keys (LiteLLM server'da kullanÄ±lacak)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
ZHIPU_API_KEY=...
```

**Not**: Provider API key'leri LiteLLM server'da olmalÄ±, Vercel'de deÄŸil (gÃ¼venlik iÃ§in).

### AdÄ±m 3: Redeploy

Environment variables ekledikten sonra:
1. Deployments sekmesine gidin
2. Son deployment'Ä±n yanÄ±ndaki "..." menÃ¼sÃ¼nden "Redeploy" seÃ§in

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§: Railway ile (5 Dakika)

### 1. Railway'de LiteLLM Deploy

**YÃ¶ntem A: Railway Template (En Kolay)**

1. [Railway LiteLLM Template](https://railway.app/template/litellm) kullanÄ±n
2. GitHub ile baÄŸlayÄ±n
3. Environment variables ekleyin:
   - `OPENAI_API_KEY`
   - `ANTHROPIC_API_KEY` (opsiyonel)
   - `LITELLM_MASTER_KEY` (gÃ¼venlik iÃ§in)

**YÃ¶ntem B: Manuel Deploy**

1. Railway'de New Project
2. New Service â†’ GitHub Repo
3. Repo: `https://github.com/BerriAI/litellm`
4. Build Command: `pip install litellm`
5. Start Command: `litellm --model gpt-3.5-turbo --port $PORT`

### 2. Railway URL'ini AlÄ±n

Railway deployment tamamlandÄ±ktan sonra:
- Settings â†’ Networking â†’ Public Domain
- URL'i kopyalayÄ±n (Ã¶rn: `https://your-litellm.up.railway.app`)

### 3. Vercel'de AyarlayÄ±n

Vercel Dashboard â†’ Environment Variables:

```env
LITELLM_API_URL=https://your-litellm.up.railway.app
LITELLM_API_KEY=your-master-key
LITELLM_MODEL=gpt-3.5-turbo
```

### 4. Redeploy

Vercel'de redeploy edin ve test edin!

## ğŸ”’ GÃ¼venlik

### LiteLLM Master Key

LiteLLM server'da master key ayarlayÄ±n:

```bash
# Railway/Render/Fly.io environment variable
LITELLM_MASTER_KEY=your-strong-random-key-here
```

Vercel'de de aynÄ± key'i kullanÄ±n:
```env
LITELLM_API_KEY=your-strong-random-key-here
```

### API Key GÃ¼venliÄŸi

- âœ… Provider API key'leri sadece LiteLLM server'da olmalÄ±
- âœ… Vercel'de sadece LiteLLM URL ve master key olmalÄ±
- âœ… Environment variables'Ä± asla commit etmeyin

## ğŸ§ª Test

Deployment sonrasÄ± test:

1. Vercel deployment'Ä±nÄ±zÄ±n URL'ine gidin
2. Chat sayfasÄ±nÄ± aÃ§Ä±n
3. Bir soru sorun
4. Console'da LiteLLM loglarÄ±nÄ± kontrol edin

## ğŸ“Š Monitoring

### LiteLLM Server LoglarÄ±

Railway/Render/Fly.io dashboard'larÄ±ndan loglarÄ± izleyebilirsiniz.

### Vercel LoglarÄ±

Vercel Dashboard â†’ Deployments â†’ Son deployment â†’ Functions sekmesinden loglarÄ± gÃ¶rebilirsiniz.

## ğŸ’° Maliyet

### LiteLLM Server Hosting

- **Railway**: $5/ay (Hobby plan) veya Ã¼cretsiz tier
- **Render**: Ãœcretsiz tier (sleep olabilir) veya $7/ay
- **Fly.io**: Ãœcretsiz tier (3 shared-cpu-1x) veya $1.94/ay
- **VPS**: $5-10/ay (DigitalOcean, Linode, vb.)

### AI Provider Maliyetleri

- **OpenAI GPT-3.5-turbo**: ~$0.0015/1K tokens (Ã§ok ucuz)
- **OpenAI GPT-4**: ~$0.03/1K tokens (pahalÄ±)
- **Claude-3-sonnet**: ~$0.003/1K tokens
- **Gemini**: Ãœcretsiz tier mevcut

## ğŸ¯ Ã–nerilen Setup (Production)

1. **LiteLLM Server**: Railway (kolay, gÃ¼venilir)
2. **Model**: `gpt-3.5-turbo` (dengeli, ucuz)
3. **Fallback**: `claude-3-haiku` (hÄ±zlÄ±, ucuz)
4. **Monitoring**: Railway logs + Vercel logs

## ğŸ”„ Model DeÄŸiÅŸtirme (Vercel'de)

Vercel Dashboard â†’ Environment Variables â†’ `LITELLM_MODEL` deÄŸerini deÄŸiÅŸtirin:

```env
# Ã–rnek: Claude-3 Sonnet'e geÃ§iÅŸ
LITELLM_MODEL=claude-3-sonnet
```

Sonra redeploy edin.

## â“ Sorun Giderme

### "Connection refused" HatasÄ±

- LiteLLM server'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun
- URL'in doÄŸru olduÄŸunu kontrol edin
- Firewall ayarlarÄ±nÄ± kontrol edin

### "401 Unauthorized" HatasÄ±

- `LITELLM_API_KEY`'in doÄŸru olduÄŸunu kontrol edin
- LiteLLM server'da master key ayarlandÄ±ÄŸÄ±ndan emin olun

### "Model not found" HatasÄ±

- `LITELLM_MODEL` adÄ±nÄ±n doÄŸru olduÄŸunu kontrol edin
- LiteLLM server'da o modelin yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±ndan emin olun

## ğŸ“š Daha Fazla Bilgi

- [LiteLLM Documentation](https://docs.litellm.ai/)
- [Railway Documentation](https://docs.railway.app/)
- [Render Documentation](https://render.com/docs)
- [Fly.io Documentation](https://fly.io/docs/)

