# GitHub AI Model Inference Setup

GitHub'Ä±n kendi AI model inference servisini kullanarak Ã¼cretsiz veya dÃ¼ÅŸÃ¼k maliyetli AI eriÅŸimi saÄŸlayabilirsiniz.

## ğŸ¯ GitHub AI AvantajlarÄ±

- âœ… **Ãœcretsiz Tier**: Rate limit'lerle Ã¼cretsiz kullanÄ±m
- âœ… **DÃ¼ÅŸÃ¼k Maliyet**: Paid usage'da token baÅŸÄ±na dÃ¼ÅŸÃ¼k fiyat
- âœ… **Kolay Kurulum**: Sadece GitHub token gerekiyor
- âœ… **Azure Entegrasyonu**: Azure Metered Billing desteÄŸi
- âœ… **Ã‡oklu Model**: GPT-5-mini, GPT-4o-mini ve daha fazlasÄ±

## ğŸ”‘ GitHub Token OluÅŸturma

### 1. GitHub Token OluÅŸturun

1. [GitHub Settings â†’ Developer settings â†’ Personal access tokens](https://github.com/settings/tokens)
2. **"Generate new token"** â†’ **"Generate new token (classic)"**
3. Token adÄ±: `CallisterAI`
4. Expiration: Ä°stediÄŸiniz sÃ¼re (veya no expiration)
5. Scopes: En azÄ±ndan `read:packages` (veya `repo` scope)
6. **"Generate token"** butonuna tÄ±klayÄ±n
7. Token'Ä± kopyalayÄ±n (bir daha gÃ¶sterilmeyecek!)

### 2. Fine-Grained Token (Ã–nerilen)

1. [GitHub Settings â†’ Developer settings â†’ Personal access tokens â†’ Fine-grained tokens](https://github.com/settings/tokens?type=beta)
2. **"Generate new token"**
3. Token name: `CallisterAI`
4. Expiration: Ä°stediÄŸiniz sÃ¼re
5. Repository access: **"All repositories"** veya belirli repo
6. Permissions â†’ **"Read access to packages"**
7. **"Generate token"**

## ğŸ”§ Environment Variables

### Local Development

**PowerShell:**
```powershell
$Env:GITHUB_TOKEN="your-github-token-here"
$Env:GITHUB_MODEL="openai/gpt-5-mini"
```

**Bash:**
```bash
export GITHUB_TOKEN="your-github-token-here"
export GITHUB_MODEL="openai/gpt-5-mini"
```

**Windows CMD:**
```cmd
set GITHUB_TOKEN=your-github-token-here
set GITHUB_MODEL=openai/gpt-5-mini
```

**Veya `.env` dosyasÄ±:**
```env
GITHUB_TOKEN=your-github-token-here
GITHUB_MODEL=openai/gpt-5-mini
```

### Vercel Production

1. Vercel Dashboard â†’ Project Settings â†’ Environment Variables
2. AÅŸaÄŸÄ±daki deÄŸiÅŸkenleri ekleyin:

```env
GITHUB_TOKEN=your-github-token-here
GITHUB_MODEL=openai/gpt-5-mini
```

3. **Redeploy** edin

## ğŸ“‹ Mevcut Modeller

GitHub AI ÅŸu modelleri destekler:

- `openai/gpt-5-mini` - En yeni, hÄ±zlÄ± ve ucuz
- `openai/gpt-4o-mini` - GPT-4o'nun mini versiyonu
- `openai/gpt-4o` - En iyi performans
- Ve daha fazlasÄ±...

GÃ¼ncel liste iÃ§in: [GitHub Models](https://github.com/models)

## ğŸ’° FiyatlandÄ±rma

### Ãœcretsiz Tier

- Rate limit'lerle sÄ±nÄ±rlÄ±
- GÃ¼nlÃ¼k/haftalÄ±k limitler
- Test ve kÃ¼Ã§Ã¼k projeler iÃ§in yeterli

### Paid Usage

- Token baÅŸÄ±na dÃ¼ÅŸÃ¼k maliyet
- Rate limit yok
- Production iÃ§in uygun

**Billing Setup:**
1. [GitHub Settings â†’ Billing](https://github.com/settings/billing)
2. Azure Metered Billing ekleyin (BYOK)
3. Veya GitHub'Ä±n kendi billing sistemini kullanÄ±n

## ğŸš€ KullanÄ±m

### Otomatik SeÃ§im

Kod otomatik olarak ÅŸu sÄ±rayÄ± takip eder:

1. **GitHub AI** (eÄŸer `GITHUB_TOKEN` varsa) âœ… Ã–ncelikli
2. **LiteLLM** (eÄŸer GitHub token yoksa, fallback)

### Model DeÄŸiÅŸtirme

`.env` dosyasÄ±nda veya Vercel environment variables'da:

```env
# GitHub AI model deÄŸiÅŸtirme
GITHUB_MODEL="openai/gpt-4o-mini"

# Veya GitHub AI'yi devre dÄ±ÅŸÄ± bÄ±rakÄ±p LiteLLM kullan
# GITHUB_TOKEN=""  # BoÅŸ bÄ±rakÄ±n
LITELLM_MODEL="gpt-3.5-turbo"
```

## ğŸ”’ GÃ¼venlik

### Token GÃ¼venliÄŸi

- âœ… Token'Ä± asla commit etmeyin
- âœ… `.env` dosyasÄ±nÄ± `.gitignore`'a ekleyin
- âœ… Vercel'de environment variables kullanÄ±n
- âœ… Token'Ä± dÃ¼zenli olarak rotate edin

### Token Permissions

- Minimum: `read:packages`
- GÃ¼venlik iÃ§in fine-grained token kullanÄ±n
- Sadece gerekli repository'lere eriÅŸim verin

## ğŸ§ª Test

### Local Test

```bash
# .env dosyasÄ±na token ekleyin
echo 'GITHUB_TOKEN=your-token' >> .env
echo 'GITHUB_MODEL=openai/gpt-5-mini' >> .env

# UygulamayÄ± baÅŸlatÄ±n
npm run dev

# Chat sayfasÄ±na gidin ve test edin
```

### Production Test

1. Vercel'de environment variables ekleyin
2. Redeploy edin
3. Chat sayfasÄ±nÄ± test edin
4. Console loglarÄ±nÄ± kontrol edin

## ğŸ“Š Monitoring

### Rate Limits

GitHub AI rate limit'lerini kontrol etmek iÃ§in:

- API response headers'da rate limit bilgisi var
- Console loglarÄ±nda gÃ¶rÃ¼necek
- Rate limit aÅŸÄ±lÄ±rsa 429 hatasÄ± alÄ±rsÄ±nÄ±z

### Usage Tracking

- GitHub Settings â†’ Billing â†’ Usage
- Azure Metered Billing dashboard (eÄŸer kullanÄ±yorsanÄ±z)

## â“ Sorun Giderme

### "401 Unauthorized" HatasÄ±

- Token'Ä±n geÃ§erli olduÄŸunu kontrol edin
- Token'Ä±n doÄŸru scope'lara sahip olduÄŸunu kontrol edin
- Token'Ä±n expire olmadÄ±ÄŸÄ±nÄ± kontrol edin

### "429 Rate Limit" HatasÄ±

- Ãœcretsiz tier limit'ine ulaÅŸtÄ±nÄ±z
- BirkaÃ§ dakika bekleyin
- Veya paid usage'a geÃ§in

### "Model not found" HatasÄ±

- `GITHUB_MODEL` adÄ±nÄ±n doÄŸru olduÄŸunu kontrol edin
- GÃ¼ncel model listesini kontrol edin: https://github.com/models

## ğŸ”„ GitHub AI'dan LiteLLM'e GeÃ§iÅŸ

GitHub AI'yÄ± devre dÄ±ÅŸÄ± bÄ±rakÄ±p LiteLLM kullanmak iÃ§in:

```env
# GitHub AI'yÄ± devre dÄ±ÅŸÄ± bÄ±rak
# GITHUB_TOKEN=""  # BoÅŸ bÄ±rakÄ±n veya silin

# LiteLLM kullan
LITELLM_API_URL="https://your-litellm-instance.com"
LITELLM_API_KEY="your-key"
LITELLM_MODEL="gpt-3.5-turbo"
```

## ğŸ“š Daha Fazla Bilgi

- [GitHub AI Documentation](https://docs.github.com/en/copilot/github-ai-model-inference)
- [GitHub Models](https://github.com/models)
- [GitHub Token Creation](https://github.com/settings/tokens)
- [Azure Metered Billing](https://docs.github.com/en/copilot/github-ai-model-inference/using-azure-metered-billing)

## ğŸ¯ Ã–nerilen Setup

**Development:**
- GitHub AI (Ã¼cretsiz tier yeterli)

**Production:**
- GitHub AI (paid usage) - En kolay ve uygun fiyatlÄ±
- Veya LiteLLM (daha fazla model seÃ§eneÄŸi)





